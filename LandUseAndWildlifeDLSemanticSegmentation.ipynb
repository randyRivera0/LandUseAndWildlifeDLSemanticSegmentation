{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/randyRivera0/LandUseAndWildlifeDLSemanticSegmentation/blob/main/LandUseAndWildlifeDLSemanticSegmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJcKeTFQyXc4"
      },
      "source": [
        "[![Cidis LandUseAndWildlifeDLSemanticSegmentation project for Galapagos and ESPOL university](https://www.cidis.espol.edu.ec/sites/default/files/default_images/logo_defecto.png)](https://www.cidis.espol.edu.ec/)\n",
        "# Train YOLO11 Object Detection on a Custom Galapagos Marine Iguana Dataset\n",
        "---\n",
        "[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/randyRivera0/LandUseAndWildlifeDLSemanticSegmentation)\n",
        "\n",
        "\n",
        "[![Roboflow](https://img.shields.io/badge/Roboflow-Dataset-orange)](https://app.roboflow.com/geckos-land/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KGpTYpMJrkI"
      },
      "source": [
        "Profesor: Phd. Miguel Andr√©s Realpe Robalino\n",
        "\n",
        "## Weekly Objectives:\n",
        "\n",
        "### Tasks\n",
        "- [ ] Join train, val and test graphics (also scale them)\n",
        "- [ ] Use best and last pt\n",
        "- [ ] Test img: separate the labels, boxes and Semantic Segmentation\n",
        "- [ ] Create new metrics with logs\n",
        "- [ ] Discover which metrics is using the system to stop the iterations and use the good ones\n",
        "- [ ] Organize and join collab with github also using a remote running server\n",
        "- [ ] Lean anout the hauid\n",
        "- [ ] Use SAM for land segmentation\n",
        "- [ ] Add more img to val\n",
        "- [ ] Use jupyter to track progress\n",
        "- [ ] Show multiple real and predict\n",
        "- [ ] Small Object Detection\n",
        "- [ ] Continue with the pretrain\n",
        "- [ ] Wandb or TensorBoard\n",
        "\n",
        "### Challenges Faced\n",
        "- Write something here\n",
        "\n",
        "### Next Steps\n",
        "- Integrate Use of Land and develop functionality for biologists\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMRrlYuYagrZ"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8G_1pU9HTw1Z",
        "outputId": "cb6d8686-64bb-48fd-df6a-5ab023aaf52e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Nov 20 01:36:09 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EcHbSY2jJrkM"
      },
      "outputs": [],
      "source": [
        "# %conda env export > environment.yml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Roboflow ultralytics"
      ],
      "metadata": {
        "id": "gCDuscLzKfyv",
        "outputId": "9eca7cc0-357a-4af6-94c4-eec52a7fd2b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Roboflow\n",
            "  Downloading roboflow-1.1.49-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.34-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from Roboflow) (2024.8.30)\n",
            "Collecting idna==3.7 (from Roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from Roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from Roboflow) (1.4.7)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from Roboflow) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from Roboflow) (1.26.4)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from Roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from Roboflow) (11.0.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from Roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from Roboflow)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from Roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from Roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from Roboflow) (2.2.3)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from Roboflow) (4.66.6)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from Roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from Roboflow) (1.0.0)\n",
            "Collecting filetype (from Roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.12-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->Roboflow) (1.3.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->Roboflow) (4.54.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->Roboflow) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->Roboflow) (3.2.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->Roboflow) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading roboflow-1.1.49-py3-none-any.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics-8.3.34-py3-none-any.whl (887 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m887.4/887.4 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.12-py3-none-any.whl (26 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: filetype, python-dotenv, idna, ultralytics-thop, ultralytics, Roboflow\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "Successfully installed Roboflow-1.1.49 filetype-1.2.0 idna-3.7 python-dotenv-1.0.1 ultralytics-8.3.34 ultralytics-thop-2.0.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "P5BsKibKJrkM",
        "outputId": "4a87160a-9f2d-48ab-ced0-db6bb1e01478",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "import __main__\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torchvision\n",
        "from roboflow import Roboflow\n",
        "from IPython.display import Image as IPyImage, display\n",
        "import ultralytics\n",
        "from ultralytics import YOLO\n",
        "import glob\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gnIrFsamJrkN",
        "outputId": "8b4524ef-337f-4704-e999-abb2af30c035",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Colab\n"
          ]
        }
      ],
      "source": [
        "# Determine runtime\n",
        "\n",
        "def in_colab():\n",
        "    from IPython.core import getipython\n",
        "    return 'google.colab' in str(getipython.get_ipython())\n",
        "\n",
        "def is_colab2():\n",
        "    try:\n",
        "        import google.colab\n",
        "        return True\n",
        "    except ImportError:\n",
        "        return False\n",
        "\n",
        "def get_runtime():\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        return \"Google Colab\"\n",
        "    elif \"ipykernel\" in sys.modules:\n",
        "        if \"jupyter\" in sys.modules:\n",
        "            return \"JupyterLab\"\n",
        "        else:\n",
        "            return \"Jupyter Notebook\"\n",
        "    elif \"win32\" in sys.platform:\n",
        "        if 'CMDEXTVERSION' in os.environ:\n",
        "            return \"Windows Command Prompt\"\n",
        "        else:\n",
        "            return \"Windows PowerShell\"\n",
        "    elif \"darwin\" in sys.platform:\n",
        "        return \"MacOS Terminal\"\n",
        "    else:\n",
        "        if hasattr(__main__,'__file__'):\n",
        "            return \"Linux Terminal\"\n",
        "        else:\n",
        "            return \"Interactive Python Shell\"\n",
        "\n",
        "print(get_runtime())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if in_colab:\n",
        "  from google.colab import userdata"
      ],
      "metadata": {
        "id": "PLFJ-JucLKLR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RiVbdtbaJrkO"
      },
      "outputs": [],
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Restrict visibility to the TITAN V only\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vbTzWXSuJrkP",
        "outputId": "a37f9f59-1a22-4c76-b3ae-d3af7ad4d37b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA disponible:\n",
            "Versi√≥n de CUDA: 12.1\n",
            "Current device: 0\n",
            "Device name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# Check if CUDA (GPU) is available\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA disponible:\")\n",
        "    print(\"Versi√≥n de CUDA:\", torch.version.cuda)\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    print(\"Current device:\", torch.cuda.current_device())  # Should output '0'\n",
        "    print(\"Device name:\", torch.cuda.get_device_name(0))   # Should output 'NVIDIA TITAN V'\n",
        "else:\n",
        "    print(\"No GPU available\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5yGhIaYoJrkS",
        "outputId": "6fa2aaa9-c245-4aa7-e3ce-8330bc0d7ed1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.5.1+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3JbEaoTDJrkS",
        "outputId": "56fa3781-6778-4b90-c037-62a3cc488a59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YAG2UV7zJrkT",
        "outputId": "4f06e716-fb4f-4e79-f2b3-59766bd24e5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu121\n",
            "0.20.1+cu121\n",
            "tensor([0], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "### NMS Test\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)\n",
        "device = 'cuda'\n",
        "boxes = torch.tensor([[0., 1., 2., 3.]]).to(device)\n",
        "scores = torch.randn(1).to(device)\n",
        "iou_threshold = 0.5\n",
        "\n",
        "print(torchvision.ops.nms(boxes, scores, iou_threshold))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRYMRidXFeIA",
        "outputId": "2752dbad-5d77-4078-e25a-94a62b981010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.34 üöÄ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 32.2/112.6 GB disk)\n"
          ]
        }
      ],
      "source": [
        "ultralytics.checks()\n",
        "HOME = Path.cwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "q2dMgiK9bBRO"
      },
      "outputs": [],
      "source": [
        "# Initialize Roboflow with your API key\n",
        "if in_colab():\n",
        "    ROBOFLOW_API_KEY = userdata.get('ROBOFLOW_API_KEY')\n",
        "    rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
        "else:\n",
        "    rf = Roboflow(api_key=\"oO7M6O03cXw3x36PVBxq\") # Replace with your actual API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuJODmnDa19o",
        "outputId": "49cdb021-230b-42ea-86a6-5dedfbb46867"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current directory: /content/datasets\n"
          ]
        }
      ],
      "source": [
        "datasets_dir = HOME / 'datasets'\n",
        "\n",
        "# Create the datasets directory (if it doesn't already exist)\n",
        "datasets_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "os.chdir(datasets_dir)\n",
        "\n",
        "# Print the current working directory\n",
        "print(f\"Current directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfnDLWrAjjnc"
      },
      "source": [
        "## Iguanas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWUqpZ1MSaQP",
        "outputId": "725da950-09e1-43c0-98ea-5745ce426ac2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in GalapagosIguanas-1 to yolov11:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7025/7025 [00:00<00:00, 11288.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to GalapagosIguanas-1 in yolov11:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 130/130 [00:00<00:00, 1074.82it/s]\n"
          ]
        }
      ],
      "source": [
        "os.chdir(datasets_dir)\n",
        "\n",
        "project = rf.workspace(\"geckos-land\").project(\"galapagosiguanas\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov11\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYsWumjWJrkV",
        "outputId": "2ad88e35-e42e-4f9f-e269-b9b4eff474fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ‚ö†Ô∏è conflicting 'task=detect' passed with 'task=segment' model. Ignoring 'task=detect' and updating to 'task=segment' to match model.\n",
            "Ultralytics 8.3.34 üöÄ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolo11l-seg.pt, data=/content/datasets/GalapagosIguanas-1/data.yaml, epochs=200, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train3\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
            "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
            "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  6                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  2   1455616  ultralytics.nn.modules.block.C2PSA           [512, 512, 2]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  2    756736  ultralytics.nn.modules.block.C3k2            [1024, 256, 2, True]          \n",
            " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  2   2365440  ultralytics.nn.modules.block.C3k2            [768, 512, 2, True]           \n",
            " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
            " 23        [16, 19, 22]  1   3718003  ultralytics.nn.modules.head.Segment          [1, 32, 256, [256, 512, 512]] \n",
            "YOLO11l-seg summary: 667 layers, 27,617,459 parameters, 27,617,443 gradients, 142.7 GFLOPs\n",
            "\n",
            "Transferred 1071/1077 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train3', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n",
            "100% 5.35M/5.35M [00:00<00:00, 106MB/s]\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/GalapagosIguanas-1/train/labels.cache... 51 images, 6 backgrounds, 0 corrupt: 100% 51/51 [00:00<?, ?it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/GalapagosIguanas-1/valid/labels.cache... 5 images, 0 backgrounds, 0 corrupt: 100% 5/5 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/segment/train3/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 176 weight(decay=0.0), 187 weight(decay=0.0005), 186 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/segment/train3\u001b[0m\n",
            "Starting training for 200 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      1/200      11.7G      2.418      4.674      3.628      1.821         25        640: 100% 4/4 [00:07<00:00,  1.85s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.89it/s]\n",
            "                   all          5         54     0.0526      0.111     0.0383      0.016     0.0614       0.13     0.0387    0.00905\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      2/200      11.4G      2.403       4.85      3.655      1.847         14        640: 100% 4/4 [00:03<00:00,  1.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  7.49it/s]\n",
            "                   all          5         54    0.00867      0.241     0.0437     0.0173    0.00733      0.204     0.0477     0.0156\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      3/200      11.5G      2.187      4.054      3.518      1.616         27        640: 100% 4/4 [00:03<00:00,  1.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.40it/s]\n",
            "                   all          5         54     0.0181      0.389      0.024    0.00672     0.0316     0.0185     0.0218     0.0059\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      4/200      11.7G      2.144      3.118      2.892      1.368        177        640:  50% 2/4 [00:02<00:02,  1.09s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\", line 969, in entrypoint\n",
            "    getattr(model, mode)(**overrides)  # default args from model\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 802, in train\n",
            "    self.trainer.train()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 207, in train\n",
            "    self._do_train(world_size)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 380, in _do_train\n",
            "    self.loss, self.loss_items = self.model(batch)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\", line 111, in forward\n",
            "    return self.loss(x, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\", line 293, in loss\n",
            "    return self.criterion(preds, batch)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/utils/loss.py\", line 287, in __call__\n",
            "    imgsz = torch.tensor(feats[0].shape[2:], device=self.device, dtype=dtype) * self.stride[0]  # image size (h,w)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "os.chdir(HOME)\n",
        "\n",
        "!yolo task=detect mode=train model=yolo11l-seg.pt data={dataset.location}/data.yaml epochs=200 imgsz=640 plots=True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(HOME)\n",
        "\n",
        "!yolo task=detect mode=train model=yolo11l-seg.pt data={dataset.location}/data.yaml epochs=200 imgsz=640 plots=True amp=False"
      ],
      "metadata": {
        "id": "OGFA7TbIREcf",
        "outputId": "5e31d986-b393-4676-fe75-b011126ed259",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ‚ö†Ô∏è conflicting 'task=detect' passed with 'task=segment' model. Ignoring 'task=detect' and updating to 'task=segment' to match model.\n",
            "Ultralytics 8.3.34 üöÄ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolo11l-seg.pt, data=/content/datasets/GalapagosIguanas-1/data.yaml, epochs=200, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=False, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train4\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
            "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
            "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  6                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  2   1455616  ultralytics.nn.modules.block.C2PSA           [512, 512, 2]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  2    756736  ultralytics.nn.modules.block.C3k2            [1024, 256, 2, True]          \n",
            " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  2   2365440  ultralytics.nn.modules.block.C3k2            [768, 512, 2, True]           \n",
            " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
            " 23        [16, 19, 22]  1   3718003  ultralytics.nn.modules.head.Segment          [1, 32, 256, [256, 512, 512]] \n",
            "YOLO11l-seg summary: 667 layers, 27,617,459 parameters, 27,617,443 gradients, 142.7 GFLOPs\n",
            "\n",
            "Transferred 1071/1077 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train4', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/GalapagosIguanas-1/train/labels.cache... 51 images, 6 backgrounds, 0 corrupt: 100% 51/51 [00:00<?, ?it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/GalapagosIguanas-1/valid/labels.cache... 5 images, 0 backgrounds, 0 corrupt: 100% 5/5 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/segment/train4/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 176 weight(decay=0.0), 187 weight(decay=0.0005), 186 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/segment/train4\u001b[0m\n",
            "Starting training for 200 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "  0% 0/4 [00:00<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\", line 969, in entrypoint\n",
            "    getattr(model, mode)(**overrides)  # default args from model\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 802, in train\n",
            "    self.trainer.train()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 207, in train\n",
            "    self._do_train(world_size)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 380, in _do_train\n",
            "    self.loss, self.loss_items = self.model(batch)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\", line 111, in forward\n",
            "    return self.loss(x, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\", line 292, in loss\n",
            "    preds = self.forward(batch[\"img\"]) if preds is None else preds\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\", line 112, in forward\n",
            "    return self.predict(x, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\", line 130, in predict\n",
            "    return self._predict_once(x, profile, visualize, embed)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\", line 151, in _predict_once\n",
            "    x = m(x)  # run\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/conv.py\", line 50, in forward\n",
            "    return self.act(self.bn(self.conv(x)))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py\", line 432, in forward\n",
            "    return F.silu(input, inplace=self.inplace)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\", line 2379, in silu\n",
            "    return torch._C._nn.silu_(input)\n",
            "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 19.06 MiB is free. Process 9555 has 118.00 MiB memory in use. Process 56709 has 14.61 GiB memory in use. Of the allocated memory 14.45 GiB is allocated by PyTorch, and 10.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Sentry is attempting to send 1 pending events\n",
            "Waiting up to 2 seconds\n",
            "Press Ctrl-C to quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After torch.OutOfMemoryError\n",
        "# PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n",
        "\n",
        "import os\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "import torch\n",
        "# Your code here\n"
      ],
      "metadata": {
        "id": "qJblm3hFORKL"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFpfatiOJrkW"
      },
      "source": [
        "### Best model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "11PjZjPpJrkW",
        "outputId": "95b0edee-5a89-418d-feea-9b045eca0f9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\", line 940, in entrypoint\n",
            "    model = YOLO(model, task=task)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/models/yolo/model.py\", line 23, in __init__\n",
            "    super().__init__(model=model, task=task, verbose=verbose)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 145, in __init__\n",
            "    self._load(model, task=task)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 285, in _load\n",
            "    self.model, self.ckpt = attempt_load_one_weight(weights)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\", line 910, in attempt_load_one_weight\n",
            "    ckpt, weight = torch_safe_load(weight)  # load ckpt\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\", line 837, in torch_safe_load\n",
            "    ckpt = torch.load(file, map_location=\"cpu\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/utils/patches.py\", line 86, in torch_load\n",
            "    return _torch_load(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1319, in load\n",
            "    with _open_file_like(f, \"rb\") as opened_file:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 659, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 640, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/runs/segment/train/weights/best.pt'\n"
          ]
        }
      ],
      "source": [
        "!yolo task=detect mode=val model={HOME}/runs/segment/train/weights/best.pt data={dataset.location}/data.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "jotBNqc2JrkW",
        "outputId": "bc873687-15f0-4f75-a2f9-d9c5a25c60da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\", line 940, in entrypoint\n",
            "    model = YOLO(model, task=task)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/models/yolo/model.py\", line 23, in __init__\n",
            "    super().__init__(model=model, task=task, verbose=verbose)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 145, in __init__\n",
            "    self._load(model, task=task)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 285, in _load\n",
            "    self.model, self.ckpt = attempt_load_one_weight(weights)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\", line 910, in attempt_load_one_weight\n",
            "    ckpt, weight = torch_safe_load(weight)  # load ckpt\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\", line 837, in torch_safe_load\n",
            "    ckpt = torch.load(file, map_location=\"cpu\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/utils/patches.py\", line 86, in torch_load\n",
            "    return _torch_load(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1319, in load\n",
            "    with _open_file_like(f, \"rb\") as opened_file:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 659, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 640, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/runs/segment/train/weights/best.pt'\n"
          ]
        }
      ],
      "source": [
        "!yolo task=detect mode=predict model={HOME}/runs/segment/train/weights/best.pt conf=0.25 source={dataset.location}/test/images save=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "bR7pRdifJrkW",
        "outputId": "fa314c52-d018-44ea-d712-159eda0b9995",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content\\\\runs\\\\segment\\\\train2\\\\confusion_matrix.png'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-801071b9e983>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mIPyImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'{HOME}\\\\runs\\\\segment\\\\train2\\confusion_matrix.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m   1229\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretina\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m         super(Image, self).__init__(data=data, url=url, filename=filename, \n\u001b[0m\u001b[1;32m   1232\u001b[0m                 metadata=metadata)\n\u001b[1;32m   1233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1261\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1264\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content\\\\runs\\\\segment\\\\train2\\\\confusion_matrix.png'"
          ]
        }
      ],
      "source": [
        "IPyImage(filename=f'{HOME}\\\\runs\\\\segment\\\\train2\\confusion_matrix.png', width=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4I6jz64cJrkX"
      },
      "outputs": [],
      "source": [
        "IPyImage(filename=f'{HOME}/runs/segment/train5/results.png', width=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VTAOwBJJrkX"
      },
      "outputs": [],
      "source": [
        "IPyImage(filename=f'{HOME}/runs/segment/train2/val_batch0_pred.jpg', width=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykHUjeJdJrkX"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "from IPython.display import Image as IPyImage, display\n",
        "\n",
        "latest_folder = max(glob.glob(f'{HOME}/runs/segment/predict2*/'), key=os.path.getmtime)\n",
        "for img in glob.glob(f'{latest_folder}/*.jpg')[:3]:\n",
        "    display(IPyImage(filename=img, width=600))\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EatowaJTJrkY"
      },
      "source": [
        "### Last model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smTOZZR8JrkY"
      },
      "outputs": [],
      "source": [
        "!yolo task=detect mode=val model={HOME}/runs/segment/train/weights/best.pt data={dataset.location}/data.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWecVwLna-NC"
      },
      "source": [
        "## Land Use\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pt-2NsETbBtF"
      },
      "outputs": [],
      "source": [
        "os.chdir(datasets_dir)\n",
        "\n",
        "project = rf.workspace(\"geckos-land\").project(\"drone-6vm9j\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov11\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBV7Eqrtb0qh"
      },
      "outputs": [],
      "source": [
        "os.chdir(HOME)\n",
        "\n",
        "!yolo task=detect mode=train model=yolo11s-seg.pt data={dataset.location}/data.yaml epochs=10 imgsz=6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XslQ6VQcOVW"
      },
      "outputs": [],
      "source": [
        "IPyImage(filename=f'{HOME}/runs/segment/train3/confusion_matrix.png', width=600)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VV8D6c5cP-8"
      },
      "outputs": [],
      "source": [
        "IPyImage(filename=f'{HOME}/runs/segment/train3/results.png', width=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJlzRY_-cSVo"
      },
      "outputs": [],
      "source": [
        "IPyImage(filename=f'{HOME}/runs/segment/train3/val_batch0_pred.jpg', width=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZh_JTkfcUxz"
      },
      "outputs": [],
      "source": [
        "!yolo task=detect mode=val model={HOME}/runs/segment/train3/weights/best.pt data={dataset.location}/data.yaml\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tQiSpK1cXCo"
      },
      "outputs": [],
      "source": [
        "!yolo task=detect mode=predict model={HOME}/runs/segment/train3/weights/best.pt conf=0.25 source={dataset.location}/test/images save=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXlBwXNccZ4U"
      },
      "outputs": [],
      "source": [
        "latest_folder = max(glob.glob(f'{HOME}/runs/segment/predict4*/'), key=os.path.getmtime)\n",
        "for img in glob.glob(f'{latest_folder}/*.jpg')[:3]:\n",
        "    display(IPyImage(filename=img, width=600))\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HM2NlW60yjUq"
      },
      "source": [
        "## References\n",
        "1. Roboflow. (2024). *Roboflow Notebooks: How to Train YOLO11 Object Detection on a Custom Dataset*. Retrieved from https://github.com/roboflow/notebooks/blob/main/notebooks/train-yolo11-object-detection-on-custom-dataset.ipynb\n",
        "how-to-train-yolov8-instance-segmentation/\n",
        "2. Roboflow. (). *Roboflow Notebooks: How to Train YOLO11 Instance Segmentation on a Custom Dataset* Retrieved from https://github.com/roboflow/notebooks/blob/main/notebooks/train-yolo11-instance-segmentation-on-custom-dataset.ipynb\n",
        "3. Ultralytics. (). *Model Training with Ultralytics YOLO* Retrieved from https://docs.ultralytics.com/modes/train/\n",
        "4. Ultralytics. *Model Training with Ultralytics YOLO* Retrieved from https://blog.roboflow.com/how-to-use-roboflow-with-aerial-imagery/\n",
        "5. Tugraz. *Semantic Drone Dataset* Retrieved from http://dronedataset.icg.tugraz.at/\n",
        "6. Ayushdabra. *Model Training with Ultralytics YOLO* Retrieved from https://github.com/ayushdabra/drone-images-semantic-segmentation\n",
        "7. Noostale. *Model Training with Ultralytics YOLO* Retrieved from https://github.com/noostale/drone-semantic-segmentation.\n",
        "8. Open Business Software Solutions. (). *slicing aided hyper inference and fine-tuning for small object detection* Retrieved from https://github.com/obss/sahi.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_jHXOuCJrkd"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "env_nms",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}